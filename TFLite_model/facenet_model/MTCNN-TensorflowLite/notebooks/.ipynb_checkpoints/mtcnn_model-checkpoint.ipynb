{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import mtcnn\n",
    "\n",
    "image_path = \"../../faces/\"\n",
    "model_path = '../models/pretrained_frozen_graphs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load graph\n",
      "['input', 'conv1/weights', 'conv1/weights/read', 'conv1/biases', 'conv1/biases/read', 'conv1/Conv2D', 'conv1/BiasAdd', 'conv1/alphas', 'conv1/alphas/read', 'conv1/Relu', 'conv1/Abs', 'conv1/sub', 'conv1/mul', 'conv1/mul_1/y', 'conv1/mul_1', 'conv1/add', 'pool1/MaxPool', 'conv2/weights', 'conv2/weights/read', 'conv2/biases', 'conv2/biases/read', 'conv2/Conv2D', 'conv2/BiasAdd', 'conv2/alphas', 'conv2/alphas/read', 'conv2/Relu', 'conv2/Abs', 'conv2/sub', 'conv2/mul', 'conv2/mul_1/y', 'conv2/mul_1', 'conv2/add', 'pool2/MaxPool', 'conv3/weights', 'conv3/weights/read', 'conv3/biases', 'conv3/biases/read', 'conv3/Conv2D', 'conv3/BiasAdd', 'conv3/alphas', 'conv3/alphas/read', 'conv3/Relu', 'conv3/Abs', 'conv3/sub', 'conv3/mul', 'conv3/mul_1/y', 'conv3/mul_1', 'conv3/add', 'pool3/MaxPool', 'conv4/weights', 'conv4/weights/read', 'conv4/biases', 'conv4/biases/read', 'conv4/Conv2D', 'conv4/BiasAdd', 'conv4/alphas', 'conv4/alphas/read', 'conv4/Relu', 'conv4/Abs', 'conv4/sub', 'conv4/mul', 'conv4/mul_1/y', 'conv4/mul_1', 'conv4/add', 'Flatten/flatten/Reshape/shape', 'Flatten/flatten/Reshape', 'fc1/weights', 'fc1/weights/read', 'fc1/biases', 'fc1/biases/read', 'fc1/MatMul', 'fc1/BiasAdd', 'fc1/Relu', 'cls_fc/weights', 'cls_fc/weights/read', 'cls_fc/biases', 'cls_fc/biases/read', 'cls_fc/MatMul', 'cls_fc/BiasAdd', 'cls_fc/Softmax', 'bbox_fc/weights', 'bbox_fc/weights/read', 'bbox_fc/biases', 'bbox_fc/biases/read', 'bbox_fc/MatMul', 'bbox_fc/BiasAdd', 'landmark_fc/weights', 'landmark_fc/weights/read', 'landmark_fc/biases', 'landmark_fc/biases/read', 'landmark_fc/MatMul', 'landmark_fc/BiasAdd', 'cls_prob', 'bbox_pred', 'landmark_pred']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "GRAPH_PB_PATH = model_path+'onet.pb'\n",
    "with tf.compat.v1.Session() as sess:\n",
    "   print(\"load graph\")\n",
    "   with tf.io.gfile.GFile(GRAPH_PB_PATH,'rb') as f:\n",
    "       graph_def = tf.compat.v1.GraphDef()\n",
    "   graph_def.ParseFromString(f.read())\n",
    "   sess.graph.as_default()\n",
    "   tf.import_graph_def(graph_def, name='')\n",
    "   graph_nodes=[n for n in graph_def.node]\n",
    "   names = []\n",
    "   for t in graph_nodes:\n",
    "      names.append(t.name)\n",
    "   print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    # We load the protobuf file from the disk and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    with tf.io.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # Then, we can use again a convenient built-in function to import a graph_def into the \n",
    "    # current default Graph\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(\n",
    "            graph_def, \n",
    "            input_map=None, \n",
    "            return_elements=None, \n",
    "            name=\"prefix\", \n",
    "            op_dict=None, \n",
    "            producer_op_list=None\n",
    "        )\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use our \"load_graph\" function\n",
    "pNet = load_graph(model_path+'pnet.pb')\n",
    "rNet = load_graph(model_path+'rnet.pb')\n",
    "oNet = load_graph(model_path+'onet.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix/input\n",
      "prefix/conv1/weights\n",
      "prefix/conv1/weights/read\n",
      "prefix/conv1/biases\n",
      "prefix/conv1/biases/read\n",
      "prefix/conv1/Conv2D\n",
      "prefix/conv1/BiasAdd\n",
      "prefix/conv1/alphas\n",
      "prefix/conv1/alphas/read\n",
      "prefix/conv1/Relu\n",
      "prefix/conv1/Abs\n",
      "prefix/conv1/sub\n",
      "prefix/conv1/mul\n",
      "prefix/conv1/mul_1/y\n",
      "prefix/conv1/mul_1\n",
      "prefix/conv1/add\n",
      "prefix/pool1/MaxPool\n",
      "prefix/conv2/weights\n",
      "prefix/conv2/weights/read\n",
      "prefix/conv2/biases\n",
      "prefix/conv2/biases/read\n",
      "prefix/conv2/Conv2D\n",
      "prefix/conv2/BiasAdd\n",
      "prefix/conv2/alphas\n",
      "prefix/conv2/alphas/read\n",
      "prefix/conv2/Relu\n",
      "prefix/conv2/Abs\n",
      "prefix/conv2/sub\n",
      "prefix/conv2/mul\n",
      "prefix/conv2/mul_1/y\n",
      "prefix/conv2/mul_1\n",
      "prefix/conv2/add\n",
      "prefix/conv3/weights\n",
      "prefix/conv3/weights/read\n",
      "prefix/conv3/biases\n",
      "prefix/conv3/biases/read\n",
      "prefix/conv3/Conv2D\n",
      "prefix/conv3/BiasAdd\n",
      "prefix/conv3/alphas\n",
      "prefix/conv3/alphas/read\n",
      "prefix/conv3/Relu\n",
      "prefix/conv3/Abs\n",
      "prefix/conv3/sub\n",
      "prefix/conv3/mul\n",
      "prefix/conv3/mul_1/y\n",
      "prefix/conv3/mul_1\n",
      "prefix/conv3/add\n",
      "prefix/conv4_1/weights\n",
      "prefix/conv4_1/weights/read\n",
      "prefix/conv4_1/biases\n",
      "prefix/conv4_1/biases/read\n",
      "prefix/conv4_1/Conv2D\n",
      "prefix/conv4_1/BiasAdd\n",
      "prefix/conv4_1/Softmax\n",
      "prefix/conv4_2/weights\n",
      "prefix/conv4_2/weights/read\n",
      "prefix/conv4_2/biases\n",
      "prefix/conv4_2/biases/read\n",
      "prefix/conv4_2/Conv2D\n",
      "prefix/conv4_2/BiasAdd\n",
      "prefix/conv4_3/weights\n",
      "prefix/conv4_3/weights/read\n",
      "prefix/conv4_3/biases\n",
      "prefix/conv4_3/biases/read\n",
      "prefix/conv4_3/Conv2D\n",
      "prefix/conv4_3/BiasAdd\n",
      "prefix/cls_prob\n",
      "prefix/bbox_pred\n",
      "prefix/landmark_pred\n"
     ]
    }
   ],
   "source": [
    "# We can verify that we can access the list of operations in the graph\n",
    "for op in pNet.get_operations():\n",
    "    print(op.name)     # <--- printing the operations snapshot below\n",
    "    # prefix/Placeholder/inputs_placeholder\n",
    "    # ...\n",
    "    # prefix/Accuracy/predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Image.open(image_path+'BillGates.jpg').resize((600, 800), Image.ANTIALIAS)\n",
    "input_image = np.asarray(image_1)[:, :, :3].reshape(1,600, 800, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We access the input and output nodes\n",
    "x_pNet = pNet.get_tensor_by_name('prefix/input:0')\n",
    "y_pNet = pNet.get_tensor_by_name('prefix/landmark_pred:0')\n",
    "\n",
    "#prefix/cls_prob\n",
    "#prefix/bbox_pred\n",
    "#prefix/landmark_pred\n",
    "\n",
    "# We launch a Session\n",
    "with tf.compat.v1.Session(graph=pNet) as sess:\n",
    "    # compute the predicted output for test_x\n",
    "    pred_y_pNet = sess.run( y_pNet, feed_dict={x_pNet: input_image} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295, 395, 2)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 600, 800, 3) for Tensor 'prefix/input:0', which has shape '(64, 24, 24, 3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-188b9a24a74a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrNet\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpred_y_rNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my_rNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_rNet\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/AI_Br_Holding/PnD/Android_App/TF_model/venvs/tf_2/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/AI_Br_Holding/PnD/Android_App/TF_model/venvs/tf_2/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1158\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 600, 800, 3) for Tensor 'prefix/input:0', which has shape '(64, 24, 24, 3)'"
     ]
    }
   ],
   "source": [
    "x_rNet = rNet.get_tensor_by_name('prefix/input:0')\n",
    "y_rNet = rNet.get_tensor_by_name('prefix/cls_prob:0')\n",
    "\n",
    "with tf.compat.v1.Session(graph=rNet) as sess:\n",
    "    pred_y_rNet = sess.run( y_rNet, feed_dict={x_rNet: input_image} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
