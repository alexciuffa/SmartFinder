{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image as Img\n",
    "import os\n",
    "\n",
    "import mtcnn\n",
    "\n",
    "from os import listdir, environ\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "my_image_path = \"../../faces/\"\n",
    "dataset_image_path = \"../../../Dataset/data/lfw/\"\n",
    "database = r\"../../../Dataset/database/SmartFinder.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input details ==\n",
      "shape: [  1 160 160   3]\n",
      "type: <class 'numpy.float32'>\n",
      "\n",
      "== Output details ==\n",
      "shape: [  1 512]\n",
      "type: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "tf_lite_model = tf.lite.Interpreter(model_path='../../tflite/facenet.tflite')\n",
    "tf_lite_model.allocate_tensors()\n",
    "\n",
    "input_details = tf_lite_model.get_input_details()\n",
    "output_details = tf_lite_model.get_output_details()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"shape:\", input_details[0]['shape'])\n",
    "print(\"type:\", input_details[0]['dtype'])\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"shape:\", output_details[0]['shape'])\n",
    "print(\"type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embedding(image_path, tf_lite_model):\n",
    "    # Open image\n",
    "    image = Img.open(image_path).convert('RGB')\n",
    "    pixels = np.asarray(image)\n",
    "    # detect faces in the image\n",
    "    detector = mtcnn.MTCNN()\n",
    "    results = detector.detect_faces(pixels)\n",
    "    # extract the bounding box from the first face\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    # extract the face\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "    # resize pixels to the model size\n",
    "    image = Img.fromarray(face)\n",
    "    image = image.resize((160, 160))\n",
    "    face_array = np.asarray(image)\n",
    "    face_array_norm = face_array /255\n",
    "    \n",
    "    input_details = tf_lite_model.get_input_details()\n",
    "    output_details = tf_lite_model.get_output_details()\n",
    "\n",
    "    tf_lite_model.set_tensor(input_details[0]['index'], face_array_norm.reshape(1,160,160,3).astype(np.float32))\n",
    "\n",
    "    tf_lite_model.invoke()\n",
    "\n",
    "    return tf_lite_model.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from datetime import datetime, timedelta\n",
    "#from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///../../../Dataset/database/SmartFinder1000.db' #'sqlite:///test.db'\n",
    "app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "db = SQLAlchemy(app)\n",
    "\n",
    "#cors = CORS(app, resources={r\"/*\": {\"origins\": \"*\"}})\n",
    "\n",
    "      #############\n",
    "########  Utils  ########\n",
    "      #############\n",
    "\n",
    "import numpy as np\n",
    "def get_distance(embedding_1, embedding_2):\n",
    "    return np.linalg.norm(np.array(eval(embedding_1)) - np.array(eval(embedding_2)))\n",
    "\n",
    "def is_new_match(json_match, new_name):\n",
    "    for match in json_match:\n",
    "        if match['person_name'] == new_name:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "      #############\n",
    "########  Models ########\n",
    "      #############\n",
    "\n",
    "class Person(db.Model):\n",
    "    id = db.Column(db.Integer, primary_key=True, autoincrement=True)\n",
    "    name = db.Column(db.String(200), nullable=False)\n",
    "    birthday = db.Column(db.DateTime, nullable=False)\n",
    "    status = db.Column(db.String(200), nullable=False)\n",
    "    created_at = db.Column(db.DateTime, nullable=True)\n",
    "    updated_at = db.Column(db.DateTime, nullable=True)\n",
    "    images = db.relationship('Image', uselist=True, backref='person')\n",
    "    matches = db.relationship('Match', uselist=True, backref='person')\n",
    "\n",
    "class Image(db.Model):\n",
    "    id = db.Column(db.Integer, primary_key=True, autoincrement=True)\n",
    "    person_id = db.Column(db.Integer, db.ForeignKey('person.id'), nullable=True)\n",
    "    path = db.Column(db.String(200), nullable=False)\n",
    "    embedding = db.Column(db.String(500), nullable=False)\n",
    "    created_at = db.Column(db.DateTime, nullable=True)\n",
    "    matches = db.relationship('Match', uselist=True, backref='image')\n",
    "\n",
    "class Request(db.Model):\n",
    "    id = db.Column(db.Integer, primary_key=True, autoincrement=True)\n",
    "    lat = db.Column(db.Integer, nullable=False)\n",
    "    long = db.Column(db.Integer, nullable=False)\n",
    "    embedding = db.Column(db.String(500), nullable=False)\n",
    "    created_at = db.Column(db.DateTime, nullable=True)\n",
    "    matches = db.relationship('Match', uselist=True, backref='request')\n",
    "\n",
    "class Match(db.Model):\n",
    "    id = db.Column(db.Integer, primary_key=True, autoincrement=True)\n",
    "    request_id = db.Column(db.Integer, db.ForeignKey('request.id'), nullable=True)\n",
    "    image_id = db.Column(db.Integer, db.ForeignKey('image.id'), nullable=True)\n",
    "    person_id = db.Column(db.Integer, db.ForeignKey('person.id'), nullable=True)\n",
    "    distance = db.Column(db.Float, nullable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = Image.query.all()\n",
    "\n",
    "db_embeddings = np.array([eval(image.embedding) for image in image_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_list = Person.query.all()\n",
    "\n",
    "person_ids = np.array([person.id for person in person_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pessoas na base:  1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Pessoas na base: \", len(person_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load new embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewPerson():\n",
    "    def __init__(self, name, embedding, _id):\n",
    "        self.name = name\n",
    "        self.embedding = embedding\n",
    "        self.id = _id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person 6: Aaron_Peirsol --- 0.07 minutes ---\n",
      "\n",
      "Total time: 0.07 minutes\n",
      "1 pessoas novas\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "new_person_list = []\n",
    "\n",
    "_id = 1\n",
    "for person_name in sorted(listdir(dataset_image_path))[0:6]:\n",
    "\n",
    "    for image_path in sorted(listdir(dataset_image_path+person_name))[3:4]:\n",
    "        embedding = get_image_embedding(dataset_image_path+person_name+'/'+image_path, tf_lite_model)\n",
    "        person = NewPerson(person_name, embedding, _id)\n",
    "        new_person_list.append(person)\n",
    "\n",
    "        print(\"Person {}: {} --- {:0.2f} minutes ---\".format(_id, person_name, (time.time() - start_time)/60))\n",
    "    _id += 1\n",
    "    \n",
    "print(\"\\nTotal time: {:0.2f} minutes\".format((time.time() - start_time)/60))\n",
    "\n",
    "new_embeddings = np.array([person.embedding for person in new_person_list])\n",
    "new_person_ids = np.array([person.id for person in new_person_list])\n",
    "\n",
    "print(\"{} pessoas novas\".format(new_person_ids.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_distance = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.linalg.norm(new_embeddings[:, None, :] - db_embeddings[None, :, :], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1295, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(distances[43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verdadeiro_positivo:  83\n",
      "verdadeiro_negativo:  26\n",
      "falso_positivo:  7\n",
      "falso_negativo:  91\n"
     ]
    }
   ],
   "source": [
    "verdadeiro_positivo = 0\n",
    "verdadeiro_negativo = 0\n",
    "falso_positivo = 0\n",
    "falso_negativo = 0\n",
    "\n",
    "for i in range(0, len(distances)):\n",
    "    if new_person_ids[i] in person_ids:\n",
    "        # Está no banco de dados e ...\n",
    "        if new_person_ids[i] in [image_list[index].person_id for index in (np.where(distances[i]<match_distance)[0])]:\n",
    "            # encontrou\n",
    "            verdadeiro_positivo += 1\n",
    "        else:\n",
    "            # não encontrou\n",
    "            verdadeiro_negativo += 1\n",
    "            \n",
    "    else:\n",
    "        # Não está no banco de dados e ...\n",
    "        if len(np.where(distances[i]<match_distance)[0]) > 0:\n",
    "            # encontrou alguém\n",
    "            falso_positivo += 1\n",
    "        else:\n",
    "            # não encontrou\n",
    "            falso_negativo += 1\n",
    "            \n",
    "print(\"verdadeiro_positivo: \", verdadeiro_positivo)\n",
    "print(\"verdadeiro_negativo: \", verdadeiro_negativo)\n",
    "print(\"falso_positivo: \", falso_positivo)\n",
    "print(\"falso_negativo: \", falso_negativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
